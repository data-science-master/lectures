---
title: "Web Scraping with rvest"
author: "David Gerard"
date: "`r Sys.Date()`"
output:  
  html_document:
    toc: true
    toc_depth: 4
urlcolor: "blue"
---


```{r setup, include=FALSE}
set.seed(1)
knitr::opts_chunk$set(echo       = TRUE, 
                      fig.height = 3, 
                      fig.width  = 6,
                      fig.align  = "center")
ggplot2::theme_set(ggplot2::theme_bw())
knitr::knit_engines$set(text = function(options) {
  # the source code is in options$code; just do
  # whatever you want with it
})
```

# Learning Objectives

- Basics of Web Scraping
- Chapter 24 of [RDS](https://r4ds.hadley.nz/)
- [Overview of rvest](https://rvest.tidyverse.org/).
- [SelectorGadget](https://rvest.tidyverse.org/articles/selectorgadget.html).
- [Web Scraping](https://r4ds.hadley.nz/webscraping.html)

# Data on the Web

- There are at least 4 ways people download data on the web:
  1. Click to download a csv/xls/txt file.
  2. Use a package that interacts with an API.
  3. Use an API directly.
  4. Scrape directly from the HTML file.
    
- This lesson, we talk about how to do 4.

- Note: You shouldn't download thousands of HTML files from a website
  to parse --- the admins might block you if you send too many requests.
  
- Note: Web scraping can be illegal in some circumstances, particularly if you intend to make money off of it or if you are collecting personal information (especially in Europe). **I don't give legal advice**, so see Chapter 24 of [RDS](https://r4ds.hadley.nz/) for some general recommendations, and talk to a lawyer if you are not sure.

-   Let's load the tidyverse:
    
    ```{r, message = FALSE}
    library(tidyverse)
    ```

# HTML / CSS

- We have to know a little bit about HTML and CSS in order to understand how to extract certain elements from a website.

- HTML stands for "HyperText Markup Language"

  ```
  <html>
  <head>
    <title>My First Web Page</title>
  </head>
  <body>
    <h1>Welcome!</h1>
    <p>This is a <b>simple</b> paragraph.</p>
    <a href="https://en.wikipedia.org/">Wikipedia</a>
  </body>
  </html>
  ```

- HTML consists of **elements** which start with a **tag** inside `<>` (like `<head>` and `<body>`), optional attributes that format the element (like `href=url`), contents (the text), and an **end tag** (like `</head>` and `</body>`). The above HTML text would be formatted like this:

<hr></hr>
<head>
  <title>My First Web Page</title>
</head>
<body>
  <h1>Welcome!</h1>
  <p>This is a <b>simple</b> paragraph.</p>
  <a href="https://youtu.be/dQw4w9WgXcQ?si=I9XnGsG7yFuKhilh">Wikipedia</a>
</body>
<hr></hr>

- Important tags for web scraping:
  - `<h1>`--`<h6>`: Heading tags, with `<h1>` as the highest (most important).
  - `<p>`: Paragraph of text.
  - `<a>`: Creates hyperlinks to other pages or resources.
  - `<img>`: Embeds an image.
  - `<div>`: Generic container for layout and styling.
  - `<span>`: Inline container for styling parts of text.
  - `<ul>`: Unordered list (bulleted).
  - `<ol>`: Ordered list (numbered).
  - `<li>`: List item, used inside `<ul>` or `<ol>`.
  - `<table>`: Defines a table structure.
  - `<tr>`: Table row.
  - `<td>`: Table data cell.
  - `<th>`: Table header cell.
  - `<strong>`: Strong importance (usually bold).
  - `<em>`: Emphasized text (usually italic).
  
- CSS stands from "Cascading Style Sheets". It's a formatting language that indicates how HTML files should look. Every website you have been on is formatted with CSS.
  
-   Here is some example CSS:

    ``` css
    h3 {
      color: red;
      font-style: italic;
    }
    
    footer div.alert {
      display: none;
    }
    ```
    
-   The part before the curly braces is called a **selector**. It corresponds
  to HTML tags. Specifically, for those two they would correspond to:
  
    ``` html
    <h3>Some text</h3>
    
    <footer>
    <div class="alert">More text</div>
    </footer>
    ```
    
- The code inside the curly braces are **properties**. For example, the h3
  properties tells us to make the h3 headers red and in italics. The second
  CSS chunk says that all `<div>` tags of class `"alert"` in the `<footer>`
  should be hidden.
  
- CSS applies the same *properties* to the same *selectors*. So every time
  we use h3 will result in the h3 styling of red and italicized text.
  
- CSS selectors define patterns for selecting HTML elements. This is useful for scraping because we can extract all text in an HTML that corresponds to some CSS selector.

- You can get a long way just selecting all `p` elements (standing for "paragraph") since that is where a lot of text lives.

- The most common attributes used are `id` and `class`. 
  - The selectors corresponding to `class` begin with a dot `.`.
  - The selectors corresponding to `id` begin with a hashtak `#`.

- The `.a` selector selects for "Text 1" in the following
  ```
  <p class="a">Text 1</p>
  ```

- The `.a` selector selects for "Text 2" in the following
  ```
  <div class="a">Text 2</div>
  ```

- The `#b` selector selects for "Text 3" in the following
  ```
  <p id="b">Text 3</p>
  ```

- The `#b` selector selects for "Text 4" in the following
  ```
  <div id="b">Text 4</div>
  ```
  
- More complicated selectors (from Richard Ressler):
  - The `name` selector just uses the `name` value of the element such as `h3`. All elements with the same name value will be selected.
  - The `id` selector uses a `#`, e.g., `#my_id`, to select a single element with `id=my_id` (all ids are unique within a page).
  - The `class` selector uses a `.`, e.g., `.my_class`, where `class=my_class`. All elements with the same class value will be selected.
  - We can combine selectors with `.`, ` `, and/or `\` to select a single element or groups of similar elements.
    - A selector of `my_name.my_class` combines name and class to select all (only) elements with the `name=my_name` and `class=my_class`.
  - The most important combinator is the white space, ` `, the descendant combination.
        As an example, `p a` selects all `<a>` elements that are a child of (nested beneath) a `<p>` element in the tree.
  - You can also find elements based on the values of attributes, e.g., find an element based on an attribute containing specific text.
    - For a partial text search you would use `'[attribute_name*="my_text"]'`. Note the combination of single quotes and double quotes so you have double quotes around the value.


# `rvest`

-   We'll use `rvest` to extract elements from HTML files.

    ```{r, message = FALSE}
    library(rvest)
    ```
    
- The typical pipeline for `rvest` is:
  - Load the html file into R using `read_html()`
  - Choose the selectors based on  SelectorGadget (see below) or by inspecting the selectors manually using developer tools (see below).
  - Select those selectors using `html_elements()`.
  - Extract the text using `html_text2()`.
    - Or, extract tables using `html_table()`.
  - Extreme cleaning using 412/612 tools.
  
-   We'll do a real example after we cover SelectorGadget and the web developer tools. But for now, let's create a small html file:

    ```{r}
    html <- minimal_html('
    <p class="a">Text 1</p>
    <div class="a">Text 2</div>
    <p id="b">Text 3</p>
    <div id="b">Text 4</div>
    ')
    ```

-   We can get all `p` tag text via
    ```{r}
    html_elements(html, "p") |>
      html_text2()
    ```

-   We can get all `div` tag text via
    ```{r}
    html_elements(html, "div") |>
      html_text2()
    ```

-   We can get all `class=a` text via
    ```{r}
    html_elements(html, ".a") |>
      html_text2()
    ```

-   We can get all `id=b` text via
    ```{r}
    html_elements(html, "#b") |>
      html_text2()
    ```

-   Once you use `html_elements()`, it's common to then use `html_element()` to extract even more information.

    ```{r}
    html_k <- minimal_html("
    <p><emph>A</emph>: <b>Ape</b> picks an <b>Apple</b> for <b>Aardvark</b> below.</p>
    <p><emph>L</emph>: <b>Lion</b> <b>Lifts</b> <b>Ladybug's</b> <b>Luggage</b></p>
    <p><emph>P</emph>: <b>Penguin</b> <b>Plays</b> with <b>Platypus</b> in the <b>Pool</b></p>
    ")
    ```

    ```{r}
    html_k |>
      html_elements("p") |>
      html_element("emph") |>
      html_text2()
    ```

-   **Exercise**: Try extracting `b` with both `html_element()` and `html_elements()`. What's the difference?

    ```{r}
    #| eval: false
    #| echo: false
    html_k |>
      html_elements("p") |>
      html_element("b") |>
      html_text2()
    html_k |>
      html_elements("p") |>
      html_elements("b") |>
      html_text2()
    # html_element() only extracts first element.
    ```


-   **Exercise** (from R4DS): Get all of the text from the `li` element below:

    ```{r}
    html <- minimal_html("
      <ul>
        <li><b>C-3PO</b> is a <i>droid</i> that weighs <span class='weight'>167 kg</span></li>
        <li><b>R4-P17</b> is a <i>droid</i></li>
        <li><b>R2-D2</b> is a <i>droid</i> that weighs <span class='weight'>96 kg</span></li>
        <li><b>Yoda</b> weighs <span class='weight'>66 kg</span></li>
      </ul>
      ")
    ```

    ```{r}
    #| echo: false
    #| eval: false
    html_elements(html, "li") |>
      html_text2()
    ```

-   **Exercise** (from R4DS): Extract the name of each droid. Start with the output of the second exercise.

    ```{r}
    #| echo: false
    #| eval: false
    html_elements(html, "li") |>
      html_element("b") |>
      html_text2()
    ```

-   **Exercise** (from R4DS): Use the class attribute of `weight` to extract the weight of each droid. Do **not** use `span`. Start with the output of the second exercise.

    ```{r}
    #| echo: false
    #| eval: false
    html_elements(html, "li") |>
      html_element(".weight") |>
      html_text2()
    ```

# SelectorGadget

- SelectorGadget is a tool for you to see what selector influences 
  a particular element on a website.

- To install SelectorGadget, drag this link to your bookmark bar on Chrome: [SelectorGadget](javascript:(function()%7Bvar%20s=document.createElement('div');s.innerHTML='Loading...';s.style.color='black';s.style.padding='20px';s.style.position='fixed';s.style.zIndex='9999';s.style.fontSize='3.0em';s.style.border='2px%20solid%20black';s.style.right='40px';s.style.top='40px';s.setAttribute('class','selector_gadget_loading');s.style.background='white';document.body.appendChild(s);s=document.createElement('script');s.setAttribute('type','text/javascript');s.setAttribute('src','https://dv0akt2986vzh.cloudfront.net/unstable/lib/selectorgadget.js');document.body.appendChild(s);%7D)();)

-   Suppose we wanted to get the top 100 movies of all time from IMDB. The
  web page is very unstructured:
  
    <https://www.imdb.com/list/ls055592025/>
    
    ![](./cartoons/IMDB_100_1.png)\ 
    
    ```{text}
    #| eval: false
    #| echo: false
    If the above link fails, try: <https://data-science-master.github.io/lectures/08_web_scraping/imdb_100.html>
    ```
    
- If we click on the ranking of the Godfather, the "1" turns green (indicating
  what we have selected).
  
  ![](./cartoons/IMDB_100_2.png)\ 
  
- The ".text-primary" is the selector associated with the "1" we clicked on.

- Everything highlighted in yellow also has the ".text-primary" selector
  associated with it.
  
- We will also want the name of the movie. So if we click on that
  we get the selector associated with both the rank and the movie name:
  "a , .text-primary".
  
  ![](./cartoons/IMDB_100_3.png)\ 
  
- But we also got a lot of stuff we don't want (in yellow). If we click
  one of the yellow items that we don't want, it turns red. This indicates
  that we don't want to select it.
  
  ![](./cartoons/IMDB_100_4.png)\ 

- Only the ranking and the name remain, which are under the selector 
  ".ipc-title-link-wrapper .ipc-title__text--reduced".
  
- It's important to visually inspect the selected elements throughout the whole
  HTML file. SelectorGadget doesn't always get all of what you want, or
  it sometimes gets too much.
  
-   **Exercise**: What selector can we use to get just the genres of each film,
  the metacritic score, and the IMDB rating?
  
    ```{text}
    #| eval: false
    #| echo: false
    ".ipl-rating-star.small .ipl-rating-star__rating , .ratings-metascore, .genre"
    ```
  
# Chrome developer tools:

- If you have trouble with SelectorGadget, you can also use the Chrome
  developer tools.
  
- Chrome works best for web scraping (better than Safari/Edge/Firefox/etc). So install it if you don't have it.
  
- Open up the list of selectors with: &#8942; > More tools > Developer tools.
  
- Clicking on the element selector on the top left of the developer tools
  will show you what selectors are possible with each element.
  
  ![](./cartoons/IMDB_100_6.png)\ 
  
# More `rvest`

- Let's do a more complicated example of `rvest`.

-   Use `read_html()` to save an HTML file to a variable. The variable will
  be an "`xml_document`" object

    ```{r}
    #| eval: false
    html_obj <- read_html("https://www.imdb.com/list/ls055592025/")
    html_obj
    class(html_obj)
    ```
    
    ```{r, eval = TRUE, echo = FALSE}
    html_obj <- read_html("./imdb_100.html")
    ```
    
- [XML](https://en.wikipedia.org/wiki/XML) stands for 
  "Extensible Markup Language". It's a markup language 
  (like HTML and Markdown), useful for representing data.
  `rvest` will store the HTML file as an XML.

-   We can use `html_elements()` and the selectors we found in the previous section 
  to get the elements we want. Insert the found selectors as the `css`
  argument.
  
    ```{r}
    ranking_elements <- html_elements(html_obj, css = ".ipc-title-link-wrapper .ipc-title__text--reduced")
    head(ranking_elements)
    ```
    
- Note: `html_element()` is similar, but will return exactly one response per element, so is useful if some elements have missing components.

-   To extract the text inside the obtained nodes, use `html_text()` or `html_text2()`:
    - `html_text2()` just does a little more pre-formatting (like converting line breaks from HTML to R code, removing white spaces, etc). So you should typically use this.

    ```{r}
    ranking_text <- html_text2(ranking_elements)
    head(ranking_text)
    ```
    
-   After you do this, you need to tidy the data using your data munging 
  tools.
  
    ```{r}
    tibble(text = ranking_text) |>
      separate(col = "text", into = c("ranking", "movie"), sep = "\\.", extra = "merge") ->
    movierank
    ```
  
-   **Exercise**: Extract the directors and the names of each film. Try to use SelectorGadget to find your own selectors. But I eventually ended up using this selector: `".kKeVOw , .ipc-title-link-wrapper .ipc-title__text--reduced"`
  
    ```{r}
    #| echo: false
    #| eval: false
    html_elements(html_obj, ".kKeVOw , .ipc-title-link-wrapper .ipc-title__text--reduced") |>
      html_text2() |>
      tibble(text = _) |>
      mutate(title = str_detect(text, "^\\d+\\."),
             rank = cumsum(title)) |>
      pivot_wider(values_from = text, names_from = title) |>
      rename(movie = `TRUE`, text = `FALSE`) |>
      mutate(
        movie = str_remove(movie, "^\\d+\\."),
        directors = str_extract(text, "Director.+Stars"),
        directors = str_remove(directors, "^Directors*"),
        directors = str_remove(directors, "Stars$")) |>
      select(-text)
    ```
    
# A very simple example

-   Here is a very simple html file that is generated using `rvest`:
    ```{r}
    html <- minimal_html("
      <h1>This is a heading</h1>
      <p id='first'>This is a paragraph</p>
      <p class='important'>This is an important paragraph</p>
    ")
    ```

-   The `h1` selector selects for `h1` tags.
    ```{r}
    html_elements(html, "h1") |>
      html_text()
    ```

-   The `.important` selector selects for `class` attribute that is `important`
    ```{r}
    html_elements(html, ".important") |>
      html_text()
    ```

-   The `#first` selector selects for `id` attribute that is `first`
    ```{r}
    html_elements(html, "#first") |>
      html_text()
    ```

  
# Bigger example using `rvest`
  
- Let's try and get the name, rank, year, metascore for each movie.

```{r}
html_elements(html_obj, ".dli-title-metadata-item:nth-child(1) , .hPmOUc, .ipc-title-link-wrapper .ipc-title__text--reduced") |>
  html_text2() |>
  tibble(text = _) |>
  mutate(
    title = str_detect(text, "\\d+\\."),
    metascore = str_detect(text, "Metascore"),
    year = !(title | metascore),
    rank = cumsum(title),
    type = case_when(
      title ~ "Title",
      year ~ "Year",
      metascore ~ "Metascore")) |>
  select(rank, text, type) |>
  pivot_wider(
    names_from = type,
    values_from = text) |>
  mutate(
    Title = str_remove(Title, "\\d+\\."),
    Metascore = str_remove(Metascore, "Metascore"),
    Title = str_squish(Title),
    Year = parse_integer(Year),
    Metascore = parse_integer(Metascore))
```



# `html_table()`

- When data is in the form of a table, you can format it more easily with
  `html_table()`.

-   The Wikipedia article on hurricanes: <https://en.wikipedia.org/wiki/Atlantic_hurricane_season>

    ```{text}
    #| eval: false
    #| echo: false
    If the above link fails, try: <https://data-science-master.github.io/lectures/08_web_scraping/wiki.html>
    ```
    
    This contains many tables which might be a pain to copy and paste
    into Excel (and we would be prone to error if we did so).
    Let's try to automate this procedure.
  
-   Save the HTML

    ```{r}
    #| eval: false
    wikixml <- read_html("https://en.wikipedia.org/wiki/Atlantic_hurricane_season")
    ```
    
    ```{r, eval = TRUE, echo = FALSE}
    wikixml <- read_html("./wiki.html")
    ```
    
-   We'll extract all of the "table" elements.

    ```{r}
    wikidat <- html_elements(wikixml, "table")
    ```

-   Use `html_table()` to get a list of tables from table elements:

    ```{r}
    tablist <- html_table(wikidat)
    class(tablist)
    length(tablist)
    tablist[[19]] |>
      select(1:4)
    ```
    
- You can clean up, bind, or merge these tables after you have read them in.

-   **Exercise**: The Wikipedia page on the oldest mosques in the world
  has many tables. 
  
    <https://en.wikipedia.org/wiki/List_of_the_oldest_mosques>
    
    ```{text}
    #| eval: false
    #| echo: false
    If the above link fails, try: <https://data-science-master.github.io/lectures/08_web_scraping/mosque.html>
    ```
  
    1. Use `rvest` to read these tables into R.
    2. Use `rvest` and SelectorGadget to extract out the category for the 
       table (mentioned in Quran, in northeast Africa, etc).
    3. Merge the data frames together. You only need to keep the building
       name, the country, and the time it was first build. 
       
    *Hint*: It's easier if you use a css selector of `"table.wikitable"`
    to get the table rather than just `"table"`. I found this out by getting
    to the developer tools in Chrome with CTRL + Shift + I then playing around
    with the tables.
    
    The first 15 rows should look like this:
       
    ```{r, echo = FALSE}
    mosque <- read_html("https://data-science-master.github.io/lectures/05_web_scraping/mosque.html")
    ```
    
    ```{r, eval = FALSE, echo = FALSE}
    mosque <- read_html("mosque.html")
    ```
    
    ```{r, echo = FALSE}
    headers <- html_text2(html_elements(mosque, css = "caption , #Mentioned_in_the_Quran"))
    tabnode  <- html_elements(mosque, css = "table.wikitable")
    tablist <- html_table(tabnode)
    
    ## length(tablist)
    ## length(headers)
    
    ## See what variables are in each table
    ## map(tablist, names)
    
    ## Table 18 doesn't have a country
    ## headers[[18]]
    tablist[[18]] |>
      mutate(Country = "Russia") ->
      tablist[[18]]
    
    ## Remove table 17 since it doesn't have the same format
    tablist[[17]] <- NULL
    
    ## table 13 has an NA row
    names(tablist[[13]])[ncol(tablist[[13]])] <- "blah"
    
    ## select variables of interest
    map(tablist, ~select(., Building, Country, fb = `First built`)) ->
      tablist
    
    ## replace, e.g., 15th century with 1500 century
    map(tablist, \(df) mutate(df, fb = str_replace(fb, "th", "00"))) |>
      map(\(df) mutate(df, fb = str_extract(fb, "^\\d+"))) ->
      tablist
    
    ## clean up headers
    str_replace_all(headers, "\\n", "") |>
      str_replace_all("\\(.+\\)", "") |>
      str_squish() ->
      headers
    
    ## add category information    
    for (index in seq_along(tablist)) {
      mutate(tablist[[index]], category = headers[[index]]) ->
        tablist[[index]]
    }
    
    ## bind rows
    bind_rows(tablist) ->
      tabdf
    
    ## print
    head(tabdf, n = 15)
    ```
